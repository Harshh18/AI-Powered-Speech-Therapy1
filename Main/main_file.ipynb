{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7167307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyts.image import GramianAngularField\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6d81101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n",
      "Recognizing...\n",
      "You said: Sorry, I could not understand audio.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "#Speech to text\n",
    "def speech_to_text():\n",
    "    recognizer = sr.Recognizer()\n",
    "#\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something...\")\n",
    "        audio = recognizer.listen(source, timeout = 1)\n",
    "\n",
    "    try:\n",
    "        print(\"Recognizing...\")\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Sorry, I could not understand audio.\"\n",
    "    except sr.RequestError as e:\n",
    "        return \"Could not request results from Google Web Speech API; {0}\".format(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    recognized_text = speech_to_text()\n",
    "    print(\"You said:\", recognized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8257adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press 'c' and Enter to stop.\n",
      "Press 'c' and Enter to stop recording: c\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import threading\n",
    "\n",
    "# Parameters\n",
    "sample_rate = 44100\n",
    "chunk_duration = 0.1  # Chunk duration in seconds\n",
    "recording = True\n",
    "audio_data = []\n",
    "\n",
    "# Function to record audio in a separate thread\n",
    "def record_audio():\n",
    "    global audio_data, recording\n",
    "    print(\"Recording... Press 'c' and Enter to stop.\")\n",
    "    while recording:\n",
    "        chunk = sd.rec(int(sample_rate * chunk_duration), samplerate=sample_rate, channels=1)\n",
    "        audio_data.extend(chunk)\n",
    "        sd.wait()\n",
    "\n",
    "# Start the audio recording thread\n",
    "recording_thread = threading.Thread(target=record_audio)\n",
    "recording_thread.start()\n",
    "\n",
    "# Wait for 'c' to be pressed\n",
    "input(\"Press 'c' and Enter to stop recording: \")\n",
    "\n",
    "# Stop recording\n",
    "recording = False\n",
    "recording_thread.join()\n",
    "\n",
    "# Convert audio data to NumPy array\n",
    "audio_data = np.concatenate(audio_data, axis=0)\n",
    "\n",
    "# Compute the Short-Time Fourier Transform (STFT)\n",
    "D = librosa.stft(audio_data)\n",
    "\n",
    "# Convert magnitude spectrogram to decibels (dB)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "# Convert decibels to text representation\n",
    "text_representation = \"\"\n",
    "for frame in S_db.T:\n",
    "    frame_text = \" \".join(map(str, frame))\n",
    "    text_representation += frame_text + \"\\n\"\n",
    "\n",
    "# Save the frequency text representation to a file\n",
    "with open(\"frequency_output.txt\", \"w\") as file:\n",
    "    file.write(text_representation)\n",
    "\n",
    "\n",
    "# # Normalize the frequency values\n",
    "# frequency_values = np.loadtxt(\"frequency_output.txt\", dtype=float)\n",
    "# normalized_frequency_values = (frequency_values - np.min(frequency_values)) / (np.max(frequency_values) - np.min(frequency_values))\n",
    "\n",
    "# # Save the normalized frequency values to a new text file\n",
    "# normalized_frequency_file_path = \"normalized_frequency_output.txt\"\n",
    "# np.savetxt(normalized_frequency_file_path, normalized_frequency_values, fmt='%.6f')\n",
    "# # ... (Previous code up to saving the normalized_frequency_output.txt file)\n",
    "\n",
    "# # Directly save each normalized frequency on a new line\n",
    "# normalized_frequency_file_path = \"normalized_frequency_output_lines.txt\"\n",
    "# with open(\"normalized_frequency_output.txt\", \"r\") as input_file, open(normalized_frequency_file_path, \"w\") as output_file:\n",
    "#     for line in input_file:\n",
    "#         values = line.strip().split()  # Split the line into individual values\n",
    "#         for value in values:\n",
    "#             float_value = float(value)\n",
    "#             output_file.write(f\"{float_value:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "69b49e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"/home/nipun/001_Hackathon/VOICED_DATASET\"\n",
    "target_folder = \"/home/nipun/001_Hackathon/imgs\"\n",
    "healthy_folder = os.path.join(target_folder, 'healthy')\n",
    "pathology_folder = os.path.join(target_folder, 'pathological')\n",
    "\n",
    "# Create the target folder if it doesn't exist\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "# List all files in the source folder\n",
    "file_list = os.listdir(source_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "030a7a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 834/834 [00:00<00:00, 22561.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# for filename in tqdm(file_list, desc=\"Processing files\"):\n",
    "#     if filename.endswith('-info.txt'):\n",
    "#         file_path = os.path.join(source_folder, filename)\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             lines = file.readlines()\n",
    "        \n",
    "#         # Find the line with the \"Diagnosis\" information\n",
    "#         diagnosis_line_index = None\n",
    "#         for i, line in enumerate(lines):\n",
    "#             if 'Diagnosis:' in line:\n",
    "#                 diagnosis_line_index = i\n",
    "#                 break\n",
    "        \n",
    "#         if diagnosis_line_index is not None:\n",
    "#             # Extract the diagnosis part and update the content\n",
    "#             diagnosis = lines[diagnosis_line_index].split(':')[1].strip()\n",
    "#             lines = [f\"{diagnosis}\"]\n",
    "        \n",
    "#             # Write the updated content back to the file\n",
    "#             with open(file_path, 'w') as file:\n",
    "#                 file.writelines(lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "287cf48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 834/834 [00:02<00:00, 280.98it/s]\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(source_folder)\n",
    "\n",
    "for filename in tqdm(file_list, desc=\"Processing files\"):\n",
    "        if filename.endswith('.txt') and not filename.endswith('-info.txt'):\n",
    "            # Read the data from the file\n",
    "            file_path = os.path.join(source_folder, filename)\n",
    "            data = pd.read_csv(file_path, delimiter='\\t')\n",
    "\n",
    "            array = data.values\n",
    "            array = np.transpose(array)\n",
    "\n",
    "            gasf = GramianAngularField(method='summation', image_size=250)\n",
    "            img1 = gasf.transform(array)\n",
    "\n",
    "            gadf = GramianAngularField(method='difference', image_size=250)\n",
    "            img2 = gadf.transform(array)\n",
    "\n",
    "            # Concatenate the transformed images\n",
    "            img = np.concatenate((img1, img2, np.zeros((1, 250, 250))), axis=0)\n",
    "\n",
    "            # Determine the label from the filename\n",
    "            info_filename = filename.replace('.txt', '-info.txt')\n",
    "            with open(os.path.join(source_folder, info_filename), 'r') as file:\n",
    "                label = file.readline().strip().split()[-1]\n",
    "\n",
    "            # Save the produced image in the appropriate folder as jpg\n",
    "            if label == 'healthy':\n",
    "                target_path = os.path.join(healthy_folder, filename.replace('.txt', '.jpg'))\n",
    "            else:\n",
    "                target_path = os.path.join(pathology_folder, filename.replace('.txt', '.jpg'))\n",
    "\n",
    "            # Convert numpy array to PIL Image and save as jpg\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "            pil_img = Image.fromarray(img)\n",
    "            pil_img.save(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4d9d9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 20\n",
    "bin_n = 32 # Number of bins\n",
    "affine_flags = cv2.WARP_INVERSE_MAP|cv2.INTER_LINEAR\n",
    "def deskew(img):\n",
    "   img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "   m = cv2.moments(img)\n",
    "   if abs(m['mu02']) < 1e-2:\n",
    "     return img.copy()\n",
    "   skew = m['mu11']/m['mu02']\n",
    "   M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])\n",
    "   img = cv2.warpAffine(img,M,(SZ, SZ),flags=affine_flags)\n",
    "   return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7d5d6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog(img):\n",
    "   gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
    "   gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
    "   mag, ang = cv2.cartToPolar(gx, gy)\n",
    "   bins = np.int32(bin_n*ang/(2*np.pi))\n",
    "   bin_cells = bins[:10,:10], bins[10:,:10], bins[:10,10:], bins[10:,10:]\n",
    "   mag_cells = mag[:10,:10], mag[10:,:10], mag[:10,10:], mag[10:,10:]\n",
    "   hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "   hist = np.hstack(hists) # hist is a 64 bit vector\n",
    "   return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "96683739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "img_folder_1 = \"/home/nipun/001_Hackathon/imgs/healthy\"\n",
    "img_folder_2 = \"/home/nipun/001_Hackathon/imgs/pathological\"\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "# Process images in folder 1\n",
    "for img_name in os.listdir(img_folder_1):\n",
    "    img_path = os.path.join(img_folder_1, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = deskew(img)\n",
    "        img = hog(img)\n",
    "        imgs.append(img)\n",
    "        labels.append(0)\n",
    "\n",
    "# Process images in folder 2\n",
    "for img_name in os.listdir(img_folder_2):\n",
    "    img_path = os.path.join(img_folder_2, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = deskew(img)\n",
    "        img = hog(img)\n",
    "        imgs.append(img)\n",
    "        labels.append(1)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "imgs = np.array(imgs)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a252bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b3ededff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(imgs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f9237093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 25ms/step - loss: 340.5479 - accuracy: 0.6106 - val_loss: 125.5729 - val_accuracy: 0.4524\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 223.3497 - accuracy: 0.6250 - val_loss: 37.8940 - val_accuracy: 0.7857\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 225.5826 - accuracy: 0.5962 - val_loss: 183.2575 - val_accuracy: 0.8333\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 159.5470 - accuracy: 0.6394 - val_loss: 44.3278 - val_accuracy: 0.7143\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 139.1917 - accuracy: 0.7212 - val_loss: 30.7226 - val_accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 130.5000 - accuracy: 0.6779 - val_loss: 50.0925 - val_accuracy: 0.8333\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 109.1563 - accuracy: 0.7740 - val_loss: 20.9720 - val_accuracy: 0.9048\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 62.3867 - accuracy: 0.7933 - val_loss: 43.5601 - val_accuracy: 0.8571\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 69.1974 - accuracy: 0.7981 - val_loss: 16.9330 - val_accuracy: 0.9286\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 66.5290 - accuracy: 0.7933 - val_loss: 2.2899 - val_accuracy: 0.9286\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2899 - accuracy: 0.9286\n",
      "Test accuracy: 0.9285714030265808\n"
     ]
    }
   ],
   "source": [
    "#DNN \n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the DNN model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(128,)),  # Input shape (number of features)\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(2, activation='softmax')  # Output layer with softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(imgs, labels, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fb48c45e",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m             img \u001b[38;5;241m=\u001b[39m hog(img)\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[0;32m---> 20\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mtxt_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(img)\n",
      "Cell \u001b[0;32mIn[140], line 17\u001b[0m, in \u001b[0;36mtxt_to_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mdeskew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     img \u001b[38;5;241m=\u001b[39m hog(img)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "Cell \u001b[0;32mIn[108], line 5\u001b[0m, in \u001b[0;36mdeskew\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeskew\u001b[39m(img):\n\u001b[0;32m----> 5\u001b[0m    img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m    m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mmoments(img)\n\u001b[1;32m      7\u001b[0m    \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmu02\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-2\u001b[39m:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "def txt_to_data():\n",
    "    with open('frequency_output.txt','r') as file:\n",
    "        data = pd.read_csv(file_path, delimiter='\\t')\n",
    "\n",
    "        array = data.values\n",
    "        array = np.transpose(array)\n",
    "        gasf = GramianAngularField(method='summation', image_size=250)\n",
    "        img1 = gasf.transform(array)\n",
    "        gadf = GramianAngularField(method='difference', image_size=250)\n",
    "        img2 = gadf.transform(array)\n",
    "        # Concatenate the transformed images\n",
    "        img = np.concatenate((img1, img2, np.zeros((1, 250, 250))), axis=0)\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        img = Image.fromarray(img)\n",
    "        if img is not None:\n",
    "            img = deskew(img)\n",
    "            img = hog(img)\n",
    "        return img\n",
    "img = txt_to_data()   \n",
    "model.predict(img)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
