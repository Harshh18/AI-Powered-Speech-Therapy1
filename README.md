<div align="center">
<h1>AI powered Speech Therapy</h1>
This repository contains the project for the hackathon which was organized by IIIT Delhi as HackCOG.
</div>

## Problem statement
In the currently increasingly associated world, there are people who face the predicament of speech and communication and hence find it extremely difficult to express themselves publicly in social settings as well as cognitive processes. The traditional forms of speech therapy are time-consuming and not very receptive. A cognitive computing-based approach powered by AI can be an optimum resort to make the speech therapy process more accessible and effective to make the communication hassle-free and even help medical professionals to aid the conventional therapy sessions. Hence, the application of the approach is slowlyÂ adaptable.

## Our solution
The proposed solution will take the cognitive computing approach into consideration and will leverage the process of aiding the conventional approaches to speech therapy as well as introducing new approaches which are dynamic as they are more receptive and effective and are more individual centric as compared to traditional ways of initiating the process through the means of real time data analysis with incorporating cognitive insights recommending personalised exercises and tracking the improvements accordingly perpetuating inclusivity in communication in social settings as well as on an individualÂ level.

## Approach to the solution
In this approach, speech analysis utilizes *Hidden Markov Models (HMM)* to detect speech patterns, like identifying specific phonemes as well as for real-time speech diagnosis. For instance, it distinguishes between "s" and "sh" sounds. *Deep Neural Networks (DNN)* refine accuracy, e.g., by recognizing subtle speech nuances, such as accents. Finally, *Mel Frequency Cepstral Coefficients (MFCC)* aid therapists by quantifying speech characteristics, like tracking progress in pronouncing "r" sounds, assessing intonation changes, and identifying voice quality deviations. This approach amalgamates HMM, DNN, and MFCC for comprehensive speech analysisÂ andÂ therapy. The implementation and working of the project has been well explained in the [ðŸ”— Loom]().

## Tech stacks used in this project
*Programming language used:*
- *Python*: Python is a versatile language commonly used in machine learning and speech processing tasks.

*Libraries and frameworks:*
- *Librosa*: A Python library for audio and music analysis. It provides tools to extract MFCCs and other audio features.
- *hmmlearn*: A library for working with Hidden Markov Models in Python.
- *TensorFlow or PyTorch*: Deep learning frameworks that allow you to build and train neural networks.
- *Scikit-learn*: A comprehensive machine learning library that includes tools for data preprocessing, model selection, and evaluation.

*Version Control*:
- *Git and Github*: A version control system and platform that helps you manage your codebase, collaborate with others, and track changes.

**IDE (Integrated Development Environment)**:
- *Jupyter Notebook*: These are popular choices for Python development, offering features like code autocompletion and debugging.
## Authors
This project has been proposed and prepared by the team *Brainstormers*.
#### Team leader
* Janvee Singh
#### Other team members
* Nipun Dhiman
* Jatin Panghal
* Harsh Khandelwal
